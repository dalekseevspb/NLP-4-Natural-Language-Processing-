# NLP-4 (Natural Language Processing, Обработка естественного языка)
# (#3) Классификация по тональности. Thematic_modeling, Тематическое моделирование
# 1) Классификация по тональности.
В этом домашнем задании вам предстоит классифицировать по тональности отзывы на банки с сайта banki.ru.
Данные содержат непосредственно тексты отзывов, некоторую дополнительную информацию, а также оценку по шкале от 1 до 5.
Тексты хранятся в json-ах в массиве responses.

# Часть 1. Анализ текстов.
а) Посчитайте количество отзывов в разных городах и на разные банки.

б) Постройте гистограммы длин слов в символах и в словах.

в) Найдите 10 самых частых:
- слов.
- слов без стоп-слов.
- лемм.
- существительных.

г) Постройте кривые Ципфа и Хипса.

д) Ответьте на следующие вопросы:
- какое слово встречается чаще, "сотрудник" или "клиент"?
- сколько раз встречаются слова "мошенничество" и "доверие"?

е) В поле "rating_grade" записана оценка отзыва по шкале от 1 до 5. Используйте меру tf-idf для того, чтобы найти ключевые слова и биграммы для положительных отзывов (с оценкой 5) и отрицательных отзывов (с оценкой 1).

# Часть 2. Тематическое моделирование.
а) Постройте несколько тематических моделей коллекции документов с разным числом тем. Приведите примеры понятных (интерпретируемых) тем.

б) Найдите темы, в которых упомянуты конкретные банки (Сбербанк, ВТБ, другой банк). Можете ли вы их прокомментировать / объяснить?
Эта часть задания может быть сделана с использованием gensim.

# Часть 3. Классификация текстов.
а) Сформулируем для простоты задачу бинарной классификации: будем классифицировать на два класса, то есть, различать резко отрицательные отзывы (с оценкой 1) и положительные отзывы (с оценкой 5).

б) Составьте обучающее и тестовое множество: выберите из всего набора данных N1 отзывов с оценкой 1 и N2 отзывов с оценкой 5 (значение N1 и N2 – на ваше усмотрение). Используйте sklearn.model_selection.train_test_split для разделения множества отобранных документов на обучающее и тестовое. Используйте любой известный вам алгоритм классификации текстов для решения задачи и получите baseline. Сравните разные варианты векторизации текста: использование только униграм, пар или троек слов или с использованием символьных n-грам.

в) Сравните, как изменяется качество решения задачи при использовании скрытых тем в качестве признаков:
- 1-ый вариант: tf-idf преобразование (sklearn.feature_extraction.text.TfidfTransformer) и сингулярное разложение (оно же – латентый семантический анализ) (sklearn.decomposition.TruncatedSVD),
- 2-ой вариант: тематические модели LDA (sklearn.decomposition.LatentDirichletAllocation). Используйте accuracy и F-measure для оценки качества классификации.

# (#7) "Классификация в NLP".
Классификация твитов covid_fake_news на фейковые/нет.
https://github.com/diptamath/covid_fake_news/tree/main/data/Constraint_Train.csv

3 раза разными способами получить на задаче классификации значение f1 выше 0.91 для методов на sklearn и выше 0.52 для методов на pytorch.

# Часть 1. Методы sklearn (лог.регрессия):
Вариант 1. Что будет, если использовать самый наивный метод (CountVectorizer)?

Вариант 2. Попробуем векторизатор Tf-Idf с параметрами по умолчанию (разбивка только на униграммы).

Вариант 3. Теперь попробуем векторизатор Tf-Idf с разбивкой твитов на n-граммы от 1 (униграмм) до 3 (триграмм).

# Часть 2. Методы на PyTorch (LSTM):
Вариант 1. Зададим максимальную длину предложений в 200 символов.

Вариант 2. Попробуем взять максимальную длину предложений 300 (вместо 200).

Вариант 3. Попробуем использовать другой оптимизатор (Adam вместо SGD) и другую функцию потерь ("Mean Squared Error" вместо "Binary Cross Entropy").

Вариант 4. Попробуем уменьшить Learning Rate с 0.01 до 0.001. Остальные параметры модели оставим, как в варианте №3.

# (#11) "Синтаксический анализ".
# Задание 1: Составление словарей для классификации по тональности.
При классификации текстов или предложений по тональности необходимо использовать оценочные словари для предметной области, то есть, такие словари, в которых содержатся отрицательные и позитивные слова для какой-то предметной области. Идея подобных словарей основана на следующих наблюдениях: во-первых, для разных товаров используются разные оценочные слова (например бывает “захватывающая книга”, но не бывает “захватывающих лыж”), во-вторых, в контексте разных товаров одни и те же слова могут иметь разную окраску (слово “тормоз” в отзыве на велосипед имеет нейтральную окраску, в отзыве на компьютер – резко негативную, “пыль” в контексте пылесосов – нейтральную, в контексте кофемолок – положительную (“мелкий помол в пыль”)). Еще один пример: "теплое пиво" – это плохо, а "теплый свитер" – это хорошо.

Составление таких словарей вручную – трудоемкий процесс, но, к счастью, его не сложно автоматизировать, если собрать достаточно большие корпуса отзывов. В этом домашнем задании вам предстоит попробовать реализовать один их подходов к составлению оценочных словарей, основанный на статье Inducing Domain-Specific Sentiment Lexicons from Unlabeled Corpora (https://nlp.stanford.edu/pubs/hamilton2016inducing.pdf).

Данные для задания – уже знакомые вам отзывы на банки, собранные с нескольких сайтов Рунета. Отзывы могут быть как положительными (оценка 5), так и отрицательными (оценка 1).

1.Разбейте всю коллекцию отзывов на предложения. Лемматизируйте все слова.

2.Обучите по коллекции предложений word2vec

3.Приведите несколько удачных и неудачных примеров решения стандартных текстов для word2vec:

-тест на определение ближайших слов

-тест на аналогии (мужчина – король : женщина – королева)

-тест на определение лишнего слова.

4.Постройте несколько визуализаций:

-TSNE для топ-100 (или топ-500) слов и найдите осмысленные кластеры слов.

Задайте координаты для нового пространства следующим образом: одна ось описывает отношение "плохо – хорошо", вторая – "медленно – быстро" и найдите координаты названий банков в этих координатах.

-Более формально: берем вектор слова "хорошо", вычитаем из него вектор слова "плохо", получаем новый вектор, который описывает разницу между хорошими и плохими словами. Берем вектор слова "сбербанк" и умножаем его на этот новый вектор – получаем координату по первой оси. Аналогично – для второй оси. Две координаты уже можно нарисовать на плоскости.

# Задание 2: Распространение метки Определите 5-8 позитивных слов (например, “быстрый”, “удобный”) и 5-8 негативных слов (например,“очередь”, “медленно”). Эти слова будут основной будущего оценочного словаря. Пусть позитивному классу соответствует метка 1, негативному – -1.

Пометьте выбранные слова в лексическом графе соответствующими метками.

Запустите любой известный вам метод распространения метки (Label Propogation) в лексическом графе. На выходе метода распространения ошибки должны быть новые слова, помеченные метками 1 и -1 – это и есть искомые оценочные слова.

Алгоритмы распространения метки устроены примерно так: пусть мы находимся в вершине, помеченной +1. С какой-то вероятностью мы переносим эту метку на соседние узлы. С меньшей вероятностью переносим ее на вершины на расстоянии два. В конце распространения метки, часть вершин оказывается помечена меткой +1, часть – -1, большая часть остается без метки.

Рекомендуемые алгоритмы распространения метки:
- graphlab.label_propagation (graphlab доступен бесплатно по образовательной лицензии)
- sklearn.semi_supervised.LabelPropagation
- sklearn.semi_supervised.LabelSpreading
